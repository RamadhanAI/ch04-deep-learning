{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3e5f0c",
   "metadata": {},
   "source": [
    "# üîç GradCAM Visualization for CNN\n",
    "Visualize CNN decision regions for MNIST-C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load trained model (assume it's available)\n",
    "model = torch.load(\"cnn_mnist_model.pt\")\n",
    "model.eval()\n",
    "\n",
    "def gradcam(input_tensor, model, target_layer):\n",
    "    gradients = []\n",
    "    activations = []\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0])\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "    handle_b = target_layer.register_backward_hook(backward_hook)\n",
    "    handle_f = target_layer.register_forward_hook(forward_hook)\n",
    "\n",
    "    output = model(input_tensor)\n",
    "    target_class = output.argmax().item()\n",
    "    model.zero_grad()\n",
    "    class_loss = output[0, target_class]\n",
    "    class_loss.backward()\n",
    "\n",
    "    grad = gradients[0][0].detach().numpy()\n",
    "    act = activations[0][0].detach().numpy()\n",
    "\n",
    "    weights = grad.mean(axis=(1, 2))\n",
    "    cam = np.sum(weights[:, None, None] * act, axis=0)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cv2.resize(cam, (28, 28))\n",
    "    cam -= cam.min()\n",
    "    cam /= cam.max()\n",
    "\n",
    "    handle_b.remove()\n",
    "    handle_f.remove()\n",
    "\n",
    "    return cam\n",
    "\n",
    "# Visualize example\n",
    "# (Assumes `input_tensor` is a preprocessed 1x1x28x28 image)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
